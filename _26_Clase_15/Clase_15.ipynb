{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyObhXOste1y0rCwFCvXAJ0y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Regresión Lineal"],"metadata":{"id":"tg62dkkjUn2C"}},{"cell_type":"markdown","source":["Objetivos:\n","* Entender que es un modelo de regresión lineal\n","* Generarlo a partir de un set de entrenamiento/testeo\n","* Evaluar las métricas para determinar que tan bien performa/generaliza\n","* Analizar un ejemplo práctico y un caso real"],"metadata":{"id":"_J7cf4lpUtvS"}},{"cell_type":"markdown","source":["## Presentamos un caso práctico"],"metadata":{"id":"qYukJf5WVSeq"}},{"cell_type":"markdown","source":["Recuerdan en clase 11 cuando estudiamos \"correlación\"?\n","<BR>\n","Habíamos generado un dataframe con alturas - pesos.\n","<BR>\n","Vamos a retomar ese ejemplo, agregando más observaciones:"],"metadata":{"id":"Slc-HQsZlWeZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"F1s3E10RRoeh"},"outputs":[],"source":["# Importamos librerias\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# Creamos las variables \"Altura_cm\" y \"Peso_kg\" con algunas observaciones\n","data = {\n","    \"Altura_cm\": [150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 158, 172, 178, 188],\n","    \"Peso_kg\":   [45, 50, 55, 58, 65, 70, 75, 80, 85, 90, 95, 53, 67, 72, 83]\n","}\n","\n","# Y con ellas creamos el dataframe df\n","df = pd.DataFrame(data)\n","\n","print(\"Primeros registros del Dataframe:\\n\", df.head())"],"metadata":{"id":"HvsC5VjhbcDx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Veamos algunas estadísticas\n","df.describe()"],"metadata":{"id":"XHXSIsXODtoY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generemos la matriz de correlacion y analizamos la relación lineal entre las variables\n","corr_matrix = df.corr()\n","corr_matrix"],"metadata":{"id":"Ca2GWF_4b0Cx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El valor 0.99 indica una fuerte asociación lineal entre las variables Altura_cm y Peso_kg, lo que sugiere que un modelo de regresión lineal podría ajustarse muy bien a estos datos.\n","<BR>\n","Generemos un gráfico de dispersión (scatterplot) y otro de dispersión pero con una linea de regresión"],"metadata":{"id":"HZ4TdcNcmK6p"}},{"cell_type":"code","source":["# Estilos y tamaños\n","plt.figure(figsize=(10,5))\n","\n","# En el subplot izquierdo, vamos a representar un scatterplot de los datos\n","plt.subplot(1,2,1)\n","sns.scatterplot(data=df, x=\"Altura_cm\", y=\"Peso_kg\", label = \"Scatterplot\")\n","\n","# En el subplot derecho, vamos a representar además una recta de regresión usnado regplot\n","plt.subplot(1,2,2)\n","sns.regplot(\n","    data=df,\n","    x=\"Altura_cm\",\n","    y=\"Peso_kg\",\n","    color=\"steelblue\",\n","    line_kws={\"color\": \"darkred\", \"label\": \"Recta de regresión\"}\n",")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"HdrsUcO3btk6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Modelo de regresión lineal simple usando sklearn"],"metadata":{"id":"5Th4juHMnMAp"}},{"cell_type":"markdown","source":["Es un modelo que predice un valor numérico usando una recta que mejor se ajusta a los datos.\n","\n","Ejemplos, predecir:\n","* Peso por altura\n","* Precio por metros cuadrados\n","* Ventas por publicidad"],"metadata":{"id":"Zpl0gWCqnTnp"}},{"cell_type":"markdown","source":["El modelo busca encontrar la mejor recta posible:\n","\n","y = b0 + b1*x\n","\n","Donde:\n","* b0: es el intercepto u ordenada al orígen\n","* b1: es la pendiente de la recta\n"],"metadata":{"id":"G6_uz2kXn0IB"}},{"cell_type":"markdown","source":["Para encontrar los coeficientes b0 y b1, el modelo usa el método de mínimos cuadrados, que busca que los puntos queden lo más cerca posible de la recta.\n","\n","La idea es minimizar\n","\n","∑(yi−y^i)2\n","\n","Es decir, cuanto más pequeños sean los errores, mejor será el modelo."],"metadata":{"id":"txALT7uDoL8w"}},{"cell_type":"markdown","source":["Para determinar que tan bueno es el modelo, se pueden utilizar estas métricas:\n","\n","* R2 (o coeficiente de determinación): cuanto más cercano a 1 mejor\n","* MSE (Mean Square Error): cuanto más pequeño mejor"],"metadata":{"id":"7nYpcc4Eov4x"}},{"cell_type":"markdown","source":["Generamos un modelo de regresión lineal"],"metadata":{"id":"7yeWIk79fNXR"}},{"cell_type":"code","source":["# Importamos las librerías\n","# train_test_split para generar los conjuntos de training/testing\n","from sklearn.model_selection import train_test_split\n","# LinearRegression para generar el modelo de Regresión Lineal\n","from sklearn.linear_model import LinearRegression\n","# métricas que usaremos para evaluar el modelo\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"],"metadata":{"id":"Sml4NsQxfQ4y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hay que particional el dataframe en dos grupos, uno de entrenamiento y otro de testing.\n","<BR>\n","Generalmente la relacion entre los conjuntos training/testing es 80/20, 75/25 o 70/30"],"metadata":{"id":"9yi0DfEtfWnh"}},{"cell_type":"code","source":["# Variables independientes o predictoras X\n","X = df[[\"Altura_cm\"]]\n","\n","# Variable objetivo o variable respuesta y\n","y = df[\"Peso_kg\"]\n","\n","# Split manual - elegimos un 80/20\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")"],"metadata":{"id":"X6DXspB2fTmB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Crear el modelo\n","model_rl = LinearRegression()"],"metadata":{"id":"QkTQpZsc7vEB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Entrenamos el modelo a partir de los datos de training\n","model_rl.fit(X_train, y_train)\n","# Internamente calcula b0 y b1"],"metadata":{"id":"RtdvU6fjg1FR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extraemos del modelo los coeficientes b0 y b1\n","b1 = model_rl.coef_[0] # es el valor de la pendiente b1\n","b0 = model_rl.intercept_ # es el valor de la ordenada al origen\n","\n","print(f\"Modelo: Peso_kg = {b0:.2f} + {b1:.2f} * Altura_cm\")"],"metadata":{"id":"IHFg3VrX8PVh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Usamos el modelo resultante para predecir los pesos (y_predict) a partir de las Alturas_cm del conjunto de testing (X_test)\n","y_pred = model_rl.predict(X_test)"],"metadata":{"id":"R7F3e1rM71s4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Métricas\n","# Queremos comparara los pesos de la predicción (y_predict) con los pesos del conjunto de testing (t_test)\n","# Calulando las métricas MSE (Mean Square Error) y R2 (Coeficiente de determinación)\n","r2 = r2_score(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","\n","print(\"R²:\", r2)\n","print(\"MSE:\", mse)"],"metadata":{"id":"04lchQROhMKa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El valor obtenido de R2 muy cercano a 1 indica un muy buen ajuste del modelo, sumado a un valor muy pequeño de MSE. Decidimos adoptar el modelo.\n","<BR>\n","Comparemos las predicciones sobre los valores de nuestro df"],"metadata":{"id":"JTLorzKP-hnR"}},{"cell_type":"code","source":["# Creamos una tercer columna llamada \"Peso_kg_pred\", generada a partir de las predicciones del modelo sobre las Alturas_cm\n","df[\"Peso_kg_pred\"] = model_rl.predict(X)\n","df"],"metadata":{"id":"H_vQMgNU-DGA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Graficamos nuevamente la dispersión de alturas - pesos\n","# Ahora usando el modelo que generamos - recta\n","plt.figure(figsize=(10,5))\n","\n","# En el primer subplot un scatterplot\n","plt.subplot(1,2,1)\n","sns.scatterplot(data=df, x=\"Altura_cm\", y=\"Peso_kg\", label=\"Scatterplot\")\n","\n","# En el segundo subplot la recta sobre el scatterplot\n","plt.subplot(1,2,2)\n","plt.scatter(X, y, label=\"Datos reales\")\n","sns.lineplot(x=X[\"Altura_cm\"], y=model_rl.predict(X), color=\"red\", label=\"Recta de regresión\")\n","\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"VHLlQEKohSo5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finalmente, usemos nuestro modelo para calcular cuál es el peso de una persona a partir de su altura"],"metadata":{"id":"d_NjQJPI_vjp"}},{"cell_type":"code","source":["# Dada la altura en cm 172, veamos cuál es su peso\n","peso = model_rl.predict([[175]])\n","print(\"El peso obtenido para una altura de 175 cm es: \", peso)"],"metadata":{"id":"6H1WlWeq_7NI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dada la altura en cm 90, veamos cuál es su peso\n","peso = model_rl.predict([[90]])\n","print(\"El peso obtenido para una altura de 120 cm es: \", peso)"],"metadata":{"id":"G-ZPT7vOAyeQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Conclusión**:\n","<BR>\n","como el modelo model_lr fue entrenado con valores de Alturas_cm comprendidas entre 150 y 190 cm, no podemos garantizar la validez de las predicciones fuera de ese rango."],"metadata":{"id":"oGgkW4tEDcCI"}},{"cell_type":"markdown","source":["##  Modelo de regresión lineal simple usando statsmodels\n","Sklearn sirve para construir modelos predictivos y no ofrece estadísticas detalladas.\n","Para obtener una tabla completa con coeficientes, p-valores e intervalos usamos statsmodels.\n","<BR>\n","Veamos entonces, a modo de referencia, como entrenar el mismo modelo de regresión lineal pero usando statsmodel"],"metadata":{"id":"_CSZZqa-FeDn"}},{"cell_type":"code","source":["import statsmodels.api as sm\n","\n","# Agregar la constante para el intercepto\n","# Agrega una columna llamada \"const\" llena de 1s a tu matriz de entrada.\n","X_sm = sm.add_constant(X)\n","\n","# Entrenar el modelo OLS\n","modelo_sm = sm.OLS(y, X_sm).fit()\n","\n","# Ver el resumen completo\n","print(modelo_sm.summary())\n","\n"],"metadata":{"id":"IDIwfwe2BUnY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predicción con intervalos de confianza\n","\n","nueva_altura = pd.DataFrame({\n","    \"const\": 1,\n","    \"Altura_cm\": [160]\n","})\n","\n","\n","pred = modelo_sm.get_prediction(nueva_altura)\n","intervalos = pred.summary_frame(alpha=0.05)  # 95% CI\n","\n","print(\"\\nPredicción con intervalos:\")\n","print(intervalos)"],"metadata":{"id":"GhhNvtsIHVwH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Con un 95% de confianza, el valor medio del peso para esta altura cae entre 54.27 y 55.18 kg."],"metadata":{"id":"dt0UdbGkJX-g"}},{"cell_type":"markdown","source":["* mean: Es la predicción puntual del modelo. Es decir, el valor estimado para esa observación.\n","* mean_se\tEs el error estándar de la predicción puntual (standard error). Mide cuánta incertidumbre tiene la predicción del valor medio.\n","* mean_ci_lower: límite inferior del intervalo de confianza del valor medio\n","* mean_ci_upper: límite inferior del intervalo de confianza del valor medio"],"metadata":{"id":"iE1-rmh8H2IX"}},{"cell_type":"markdown","source":["# Aplicamos a un caso real"],"metadata":{"id":"HdNqipowGMzw"}},{"cell_type":"markdown","source":["## Carga de datos + EDA"],"metadata":{"id":"RmQ7aVZ5SxZ9"}},{"cell_type":"markdown","source":["Vamos a trabajar con un dataset de precios de propiedades de Amsterdam\n","[Dataset en Github](https://raw.githubusercontent.com/kuntala-c/Amsterdam-Housing-Price-Analysis/refs/heads/main/HousingPrices-Amsterdam-August-2021.csv)"],"metadata":{"id":"ykfY2f0F-jOd"}},{"cell_type":"code","source":["# Cargamos librerias\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"metadata":{"id":"2kR_rGU5GQV_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importamos el dataset desde Github\n","\n","url = \"https://raw.githubusercontent.com/kuntala-c/Amsterdam-Housing-Price-Analysis/refs/heads/main/HousingPrices-Amsterdam-August-2021.csv\"\n","df = pd.read_csv(url)\n","\n","df.head()\n"],"metadata":{"id":"tRkkxZYE-8EF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Lo que nos interesa predecir es el valor de la propiedad a partir de los metros cuadrados, es decir, generar un modelo al que yo le pase los metros cuadrados de una propiedad y me retorne el precio.\n","<BR>\n","Por lo tanto, de nuestro dataset, las variables de importancia van a ser:\n","\n","* Area: variable independiente o predictora\n","* Price: variable dependiente u objetivo"],"metadata":{"id":"vP4h1KXOBb81"}},{"cell_type":"code","source":["# Analicemos el dataframe, si hay nulos y tipo de datos\n","df.info()"],"metadata":{"id":"R3r_p2s9Aha8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notamos que la variable a predecir Price es del tipo float64, pero Area, que es nuestra variable predictora del tipo object. Eso se debe a que algun valor es no numerico, veamos de resolverlo:"],"metadata":{"id":"1NodUeGSBZrl"}},{"cell_type":"code","source":["# Usamos pd.to_numeric para convertir object a floar y errors='coerce'\n","# para que complete con NaN aquellos valores que no pueda convertir\n","df[\"Area\"] = pd.to_numeric(df[\"Area\"], errors='coerce')\n","\n","# Y luego removemos los NaN\n","df = df.dropna(subset=[\"Area\", \"Price\"])\n"],"metadata":{"id":"rHrC4ewXCWu-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Veamos algunas estadísticas\n","df.describe()"],"metadata":{"id":"9A88IYpmA4ol"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Seleccionamos solo las columnas que nos interesan\n","df = df[[\"Area\", \"Price\"]]\n","df.head()"],"metadata":{"id":"j7EhYlJ__J_V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generemos un Histograma para analizar la distribución de las frecuencias de Price y Area\n","plt.figure(figsize=(10,5))\n","\n","plt.subplot(1,2,1)\n","sns.histplot(data=df, x=\"Price\")\n","plt.title(\"Distribución de los precios\")\n","\n","plt.subplot(1,2,2)\n","sns.histplot(data=df, x=\"Area\")\n","plt.title(\"Distribución de las superficies\")"],"metadata":{"id":"ml4kZ5wT_eol"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generemos un Boxplot para analizar las medidas cenrtales de Price y Area\n","plt.figure(figsize=(10,5))\n","\n","plt.subplot(1,2,1)\n","sns.boxplot(data=df, x=\"Price\")\n","plt.title(\"Medidas centrales de precios\")\n","\n","plt.subplot(1,2,2)\n","sns.boxplot(data=df, x=\"Area\")\n","plt.title(\"Medidas centrales de superficies\")"],"metadata":{"id":"3lgiTv8d_0et"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,5))\n","\n","plt.subplot(1,2,1)\n","sns.scatterplot(data=df, y=\"Price\", x=\"Area\")\n","plt.title(\"Dispersión Precios - Superficies\")\n","\n","plt.subplot(1,2,2)\n","sns.regplot(\n","    data=df,\n","    x=\"Area\",\n","    y=\"Price\",\n","    color=\"steelblue\",\n","    line_kws={\"color\": \"darkred\", \"label\": \"Recta de regresión\"}\n",")\n","plt.title(\"Dispersión Precios - Superficies + regresión\")"],"metadata":{"id":"g58muIZbAGQV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Veamos ahora el nivel de asociación lineal entre las variables.\n","<BR>\n","Siii para eso tenemos la matriz de correlación"],"metadata":{"id":"h04iUDrBA2Bw"}},{"cell_type":"code","source":["# Usamos el método corr() para generar la matriz de correlación\n","correlacion = df.corr()\n","correlacion"],"metadata":{"id":"fYymJm96FvSV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Un valor de 0.83 indica fuerte asociación lineal, asi que generemos nuestro modelo de regresión lineal!"],"metadata":{"id":"NaWPH1cQMZ_E"}},{"cell_type":"markdown","source":["## Generamos el modelo de regresión lineal"],"metadata":{"id":"utgU-SQ1S4Sk"}},{"cell_type":"code","source":["# Importamos las librerías\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np"],"metadata":{"id":"C9PkL7QyMk2s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hay que particional el dataframe en dos grupos, uno de entrenamiento y otro de testing.\n","Generalmente la relacion entre los conjuntos training/testing es 80/20, 75/25 o 70/30"],"metadata":{"id":"GNub4VmCMvgU"}},{"cell_type":"code","source":["# Variables independientes o predictoras X\n","X = df[[\"Area\"]]\n","\n","# Variable objetivo o variable respuesta y\n","y = df[\"Price\"]\n","\n","# Split manual - elegimos un 80/20\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")"],"metadata":{"id":"AbCI36ybMz7s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Crear el modelo\n","model_rl = LinearRegression()"],"metadata":{"id":"sgsacrHSMvUW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Entrenamos el modelo a partir de los datos de training\n","model_rl.fit(X_train, y_train)"],"metadata":{"id":"e0WwW2T1M-FV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["b1 = model_rl.coef_[0]\n","b0 = model_rl.intercept_\n","\n","print(f\"Modelo: Price = {b0:.2f} + {b1:.2f} * Area\")"],"metadata":{"id":"nx7UKKWsNGrM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Usamos el modelo resultante para predecir los pesos (y_predict) a partir de las Alturas_cm del conjunto de testing (X_test)\n","y_pred = model_rl.predict(X_test)"],"metadata":{"id":"vWZrIQfUNOxl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Métricas\n","# Queremos comparara los precios de la predicción (y_predict) con los precios del conjunto de testing (t_test)\n","# Calulando las métricas MSE (Mean Square Error) y R2 (Coeficiente de determinación)\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","\n","print(\"MSE:\", mse)\n","print(\"RMSE:\", rmse)\n","print(\"R²:\", r2)"],"metadata":{"id":"b3I9Fd8pNV3k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dada la superficie de una casa, veamos cuál es su precio\n","price = model_rl.predict([[100]])\n","print(\"El precio obtenido para una altura de 100 cm es: \", price)"],"metadata":{"id":"SXRRjPdCNui0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Conclusión**:\n","<BR>\n","En este análisis aplicamos un modelo de regresión lineal simple para estudiar la relación entre las variables del dataset. Si bien observamos una asociación moderadamente fuerte (r ≈ 0.8), el modelo no logró capturar toda la variabilidad presente en los datos. Esto se refleja en un R² limitado, que indica que una parte importante del comportamiento de la variable objetivo no puede explicarse únicamente mediante una relación lineal.\n","\n","Además, la presencia de cierta dispersión, valores atípicos y posibles relaciones no lineales sugiere que la regresión lineal puede no ser el modelo más adecuado para este problema. La estructura de los datos podría requerir modelos más flexibles, capaces de adaptarse a patrones complejos sin imponer la restricción de linealidad.\n","\n","En este sentido, resulta natural dejar abierta la exploración de técnicas de Machine Learning más avanzadas, como:\n","\n","* Árboles de decisión para regresión\n","* Random Forest\n","* Gradient Boosting (XGBoost, LightGBM)\n","* k-Nearest Neighbors (KNN) Regressor\n","* Modelos polinomiales o no lineales\n","\n","Estos modelos permiten capturar relaciones más complejas, manejar mejor la interacción entre variables y, en muchos casos, ofrecen un desempeño predictivo superior.\n","\n","En resumen: la regresión lineal es un excelente punto de partida para comprender relaciones básicas, pero este caso muestra la importancia de avanzar hacia modelos de Machine Learning capaces de adaptarse mejor a la estructura real de los datos."],"metadata":{"id":"hh6-A8HXPCDc"}}]}